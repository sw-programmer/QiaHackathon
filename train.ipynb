{"cells":[{"cell_type":"markdown","metadata":{"id":"6cU4hofynAuo"},"source":["# Set up environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6BofWjRAmbcc"},"outputs":[],"source":["# Uncomment below section and run in case of re-connecting Colab\n","\n","# !pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n","# !pip install transformers\n","# !pip install git+https://github.com/ssut/py-hanspell.git\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# %cd drive/MyDrive/MBTI\n","# !pwd"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3888,"status":"ok","timestamp":1679420610053,"user":{"displayName":"박상우","userId":"00596815453416531190"},"user_tz":-540},"id":"DyiXeOjimgi9"},"outputs":[],"source":["from dataloader import MBTIDataset\n","\n","import pandas as pd\n","pd.set_option('display.width', 180)\n","import torch\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","from sklearn.model_selection import KFold\n","from transformers import DataCollatorWithPadding, BertForSequenceClassification, BertConfig"]},{"cell_type":"markdown","metadata":{"id":"ARc_jwe5nF8g"},"source":["# Prepare dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679419300235,"user":{"displayName":"박상우","userId":"00596815453416531190"},"user_tz":-540},"id":"Ef5Z75ozmW8m"},"outputs":[],"source":["# Setup\n","env_dict = {\n","    # ==== Arguments for dataset =====\n","    'train_path'        : './data/example_train.csv',\n","    'question_path'     : './data/question_filtered.csv',\n","    'target'            : 'E',\n","    'pretrained_url'    : \"klue/bert-base\",\n","    'padding_per_batch' : True,\n","    # ==== Arguments for dataloader =====\n","    'shuffle'           : False,            # turn off 'shuffle' since we use sampler in Dataloader\n","    # ==== Arguments for training =====\n","    'batch_size'        : 64,\n","    'epoch'             : 100,\n","    'lr'                : 1e-4\n","\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzufA7B9mW8o"},"outputs":[],"source":["# Dataset\n","train_dataset = MBTIDataset(\n","    data_path           = env_dict['train_path'],\n","    question_path       = env_dict['question_path'],\n","    target_mbti         = env_dict['target'],\n","    pretrained_url      = env_dict['pretrained_url'],\n","    padding_per_batch   = env_dict['padding_per_batch'],\n","    is_train            = True\n",")\n","\n","print(len(train_dataset))\n","print(train_dataset.data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBo4Xtc6oCls"},"outputs":[],"source":["# define collator function when padding per batch is needed\n","#TODO: data_collator가 아닌 torch의 Packing 을 이용하는 것과 성능 비교가 필요함\n","data_collator = DataCollatorWithPadding(tokenizer=train_dataset.tokenizer) if env_dict['padding_per_batch'] else None\n","\n","# Dataloader\n","train_dataloder = DataLoader(\n","    train_dataset,\n","    batch_size  = env_dict['batch_size'],\n","    shuffle     = env_dict['shuffle'],\n","    collate_fn  = data_collator\n",")"]},{"cell_type":"markdown","metadata":{"id":"60pvecWkpznO"},"source":["# Prepare model"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1679420610053,"user":{"displayName":"박상우","userId":"00596815453416531190"},"user_tz":-540},"id":"tbVO_n8BQ1bc","outputId":"449e52b5-11e0-46db-8bdd-97170a314765"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}],"source":["# GPU preparation\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using CPU instead.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBnG6HDWmW8p"},"outputs":[],"source":["# Model\n","model = BertForSequenceClassification.from_pretrained(env_dict['pretrained_url'], num_labels=2)\n","model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"Xsg8RoRjXjQE"},"source":["# Train & CV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-DVssQfmW8p"},"outputs":[],"source":["# Training with cross validation (ref : https://velog.io/@pppanghyun/6.-%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9DCross-Validation)\n","\n","kfold     = KFold(n_splits=5, shuffle=True)\n","criterion = torch.nn.MSELoss()\n","\n","validation_loss = []\n","\n","for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n","\n","    # Make indices for both training and validation\n","    train_subsampler  = SubsetRandomSampler(train_idx)\n","    val_subsampler    = SubsetRandomSampler(val_idx)\n","    \n","    # Define dataloader using sampler\n","    train_dataloder = DataLoader(\n","        train_dataset,\n","        batch_size  = env_dict['batch_size'],\n","        shuffle     = env_dict['shuffle'],\n","        sampler     = train_subsampler,\n","        collate_fn  = data_collator\n","    )\n","    val_dataloder   = DataLoader(\n","        train_dataset,\n","        batch_size  = env_dict['batch_size'],\n","        shuffle     = env_dict['shuffle'],\n","        sampler     = val_subsampler,\n","        collate_fn  = data_collator\n","    )\n","\n","    # ===================\n","    #    Training Loop\n","    # ===================\n","\n","#     model = Regressor()\n","#     optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-7)\n","\n","#     for epoch in range(400): # 400번 학습을 진행한다.\n","\n","#         for data in trainloader: # 무작위로 섞인 32개 데이터가 있는 배치가 하나 씩 들어온다.\n","\n","#             inputs, values = data # data에는 X, Y가 들어있다.\n","\n","#             optimizer.zero_grad() # 최적화 초기화\n","\n","#             outputs = model(inputs) # 모델에 입력값 대입 후 예측값 산출\n","#             loss = criterion(outputs, values) # 손실 함수 계산\n","#             loss.backward() # 손실 함수 기준으로 역전파 설정 \n","#             optimizer.step() # 역전파를 진행하고 가중치 업데이트\n","\n","#     train_rmse = evaluation(trainloader) # 학습 데이터의 RMSE\n","#     val_rmse = evaluation(valloader)\n","#     print(\"k-fold\", fold,\" Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse)) \n","#     validation_loss.append(val_rmse)\n","\n","## Calculate validation score\n","\n","# validation_loss = np.array(validation_loss)\n","# mean = np.mean(validation_loss)\n","# std = np.std(validation_loss)\n","# print(\"Validation Score: %.4f, ± %.4f\" %(mean, std))"]},{"cell_type":"markdown","metadata":{"id":"1LUMI4BiZVac"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKT0AC3LZWke"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7337906654535f92ad925780206611836a0922d3540b9d89ec64204ed4b58f9b"}}},"nbformat":4,"nbformat_minor":0}
