{"cells":[{"cell_type":"markdown","metadata":{"id":"6cU4hofynAuo"},"source":["# Set up environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6BofWjRAmbcc"},"outputs":[],"source":["# Uncomment below section and run in case of re-connecting Colab\n","\n","!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n","!pip install transformers\n","!pip install git+https://github.com/ssut/py-hanspell.git\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 영도야 여긴 너 경로에 맞게 바꿔야 할거야\n","%cd drive/MyDrive/MBTI\n","!pwd"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"DyiXeOjimgi9","executionInfo":{"status":"ok","timestamp":1680543689977,"user_tz":-540,"elapsed":14866,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"outputs":[],"source":["import time\n","import datetime\n","import random\n","from tqdm import tqdm\n","import pickle\n","\n","from dataloader import MBTIDataset\n","\n","import pandas as pd\n","pd.set_option('display.width', 180)\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","from sklearn.model_selection import KFold\n","from transformers import DataCollatorWithPadding, BertForSequenceClassification, BertConfig, AdamW"]},{"cell_type":"markdown","metadata":{"id":"ARc_jwe5nF8g"},"source":["# Environment"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"Ef5Z75ozmW8m","executionInfo":{"status":"ok","timestamp":1680544039888,"user_tz":-540,"elapsed":1,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"outputs":[],"source":["# Setup\n","env_dict = {\n","    # ==== Arguments for dataset =====\n","    'train_path'        : './data/hackathon_train_v1.csv',\n","    'question_path'     : './data/question_filtered.csv',\n","    'test_path'         : './data/hackathon_test_for_user.csv'\n","    'pretrained_url'    : \"klue/bert-base\",\n","    'padding_per_batch' : True,\n","    # ==== Arguments for dataloader =====\n","    'shuffle'           : False,            # turn off 'shuffle' since we use sampler in Dataloader\n","    # ==== Arguments for training =====\n","    'target'            : 'I/E',\n","    'lm'                : 'bert',\n","    'classifier'        : 'mlp',\n","    'batch_size'        : 16,\n","    'epoch'             : 5,\n","    'lr'                : 1e-2,\n","    'decay_rate'        : 1e-7,\n","    'dropout'           : 0.1,\n","    'hidden_dim'        : [192, 48, 12]     # 일단 설정해둔 숫자들 (cls token의 dimension인 768 을 4로 나눈 값들)\n","}\n","\n","# Random seed\n","seed_val = 1234\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"code","source":["# Garbage collect\n","import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"EXNJJ7ZpWDwI","executionInfo":{"status":"ok","timestamp":1680544044355,"user_tz":-540,"elapsed":497,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["# Prepare dataset"],"metadata":{"id":"OmT20qIS3CfU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzufA7B9mW8o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680499653644,"user_tz":-540,"elapsed":615983,"user":{"displayName":"박상우","userId":"00596815453416531190"}},"outputId":"b5003c42-20f6-45d6-ebb7-e9cb78278356"},"outputs":[{"output_type":"stream","name":"stdout","text":["=============== fix_spacing ===============\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11520/11520 [10:07<00:00, 18.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=============== remove_punctuation ===============\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11520/11520 [00:00<00:00, 31081.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=============== prepare_binary_classification ===============\n"]},{"output_type":"stream","name":"stderr","text":["4it [00:00, 65.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=============== tokenize ===============\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11520/11520 [00:06<00:00, 1737.02it/s]"]},{"output_type":"stream","name":"stdout","text":["11520\n","   Data_ID  User_ID  Gender       Age  MBTI  Q_number                                             Answer  I/E  S/N  T/F  J/P                                        QandA\n","0        1        1       1 -0.372581  INFP         1  <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...    0    1    1    1  [input_ids, token_type_ids, attention_mask]\n","1        2        1       1 -0.372581  INFP         2  <중립> 다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하며...    0    1    1    1  [input_ids, token_type_ids, attention_mask]\n","2        3        1       1 -0.372581  INFP         3  <그렇다> 감정이입이 잘 되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...    0    1    1    1  [input_ids, token_type_ids, attention_mask]\n","3        4        1       1 -0.372581  INFP         4  <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다일의 변수가 생길 수 있고 변...    0    1    1    1  [input_ids, token_type_ids, attention_mask]\n","4        5        1       1 -0.372581  INFP         5  <아니다> 평정심을 유지 못하는 편입니다 머릿속은 백지화가 된 상태로 말도 제대로 ...    0    1    1    1  [input_ids, token_type_ids, attention_mask]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Uncomment & run this cell only if there is no preprocessed data\n","\n","# Dataset\n","# train_dataset = MBTIIDataset(\n","#     data_path           = env_dict['train_path'],\n","#     question_path       = env_dict['question_path'],\n","#     pretrained_url      = env_dict['pretrained_url'],\n","#     padding_per_batch   = env_dict['padding_per_batch'],\n","#     txt_preprocess      = True,\n","#     is_train            = True\n","# )\n","\n","# print(len(train_dataset))\n","# print(train_dataset.data.head())"]},{"cell_type":"code","source":["# Uncomment & run this cell only if there is no preprocessed data\n","\n","# # save preprocessed pd.Dataframe & tokenizer as pickle data format\n","\n","data_path = './data/' + 'base_data_2.pickle'\n","# with open(data_path, 'wb') as handle:\n","#     pickle.dump(train_dataset.data, handle)\n","\n","# with open('./data/base_tokenizer.pickle', 'wb') as handle:\n","#     pickle.dump(train_dataset.tokenizer, handle)"],"metadata":{"id":"r99ktXNBztto","executionInfo":{"status":"ok","timestamp":1680543690379,"user_tz":-540,"elapsed":2,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Load data as pd.DataFrame & tokenizer\n","from dataloader import MBTIDataset\n","\n","with open(data_path, 'rb') as handle:\n","    df = pickle.load(handle)\n","\n","with open('./data/base_tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","\n","train_dataset = MBTIDataset(\n","    data_path           = df,\n","    question_path       = env_dict['question_path'],\n","    pretrained_url      = env_dict['pretrained_url'],\n","    padding_per_batch   = env_dict['padding_per_batch'],\n","    is_train            = True\n",")\n","\n","print(len(train_dataset))\n","print(train_dataset.data.head())"],"metadata":{"id":"kN0d5eTQWLNV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680543692190,"user_tz":-540,"elapsed":1813,"user":{"displayName":"박상우","userId":"00596815453416531190"}},"outputId":"a7dcdb78-f730-442e-b660-ea6fc97ce692"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["11520\n","   Data_ID  User_ID  Gender       Age  MBTI  Q_number                                             Answer  I/E  S/N  T/F  J/P                                              QandA\n","0        1        1       1 -0.372581  INFP         1  <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...    0    1    1    1  [input_ids, token_type_ids, attention_mask, ca...\n","1        2        1       1 -0.372581  INFP         2  <중립> 다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하며...    0    1    1    1  [input_ids, token_type_ids, attention_mask, ca...\n","2        3        1       1 -0.372581  INFP         3  <그렇다> 감정이입이 잘 되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...    0    1    1    1  [input_ids, token_type_ids, attention_mask, ca...\n","3        4        1       1 -0.372581  INFP         4  <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다일의 변수가 생길 수 있고 변...    0    1    1    1  [input_ids, token_type_ids, attention_mask, ca...\n","4        5        1       1 -0.372581  INFP         5  <아니다> 평정심을 유지 못하는 편입니다 머릿속은 백지화가 된 상태로 말도 제대로 ...    0    1    1    1  [input_ids, token_type_ids, attention_mask, ca...\n"]}]},{"cell_type":"code","execution_count":44,"metadata":{"id":"wBo4Xtc6oCls","executionInfo":{"status":"ok","timestamp":1680544050171,"user_tz":-540,"elapsed":3,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"outputs":[],"source":["# define collator function when padding per batch is needed\n","#TODO: data_collator가 아닌 torch의 Packing 을 이용하는 것과 성능 비교가 필요함\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer) if env_dict['padding_per_batch'] else None\n","\n","# Dataloader\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size  = env_dict['batch_size'],\n","    shuffle     = env_dict['shuffle'],\n","    collate_fn  = data_collator\n",")"]},{"cell_type":"code","source":["# Example result from dataloader\n","import pprint\n","pprint.pprint(next(iter(train_dataloader)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFvIVkJqBinP","executionInfo":{"status":"ok","timestamp":1680543692190,"user_tz":-540,"elapsed":5,"user":{"displayName":"박상우","userId":"00596815453416531190"}},"outputId":"ec6b3c03-4bc8-4112-c02f-5da16dff7771"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"stream","name":"stdout","text":["{'I/E': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'J/P': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'S/N': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'T/F': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]),\n"," 'cat_input': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'input_ids': tensor([[    2,  7267, 11187,  ...,     0,     0,     0],\n","        [    2,  3936,  3641,  ...,     0,     0,     0],\n","        [    2,  3656,  3611,  ...,     0,     0,     0],\n","        ...,\n","        [    2,  4051,  4362,  ...,     0,     0,     0],\n","        [    2,  3656,  3611,  ...,     0,     0,     0],\n","        [    2,  3971,  3746,  ...,     0,     0,     0]]),\n"," 'num_input': tensor([-0.3726, -0.3726, -0.3726, -0.3726, -0.3726, -0.3726, -0.3726, -0.3726,\n","        -0.3726, -0.3726, -0.3726, -0.3726, -0.3726, -0.3726, -0.3726, -0.3726],\n","       dtype=torch.float64),\n"," 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]])}\n"]}]},{"cell_type":"markdown","metadata":{"id":"60pvecWkpznO"},"source":["# Prepare language model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680543692191,"user":{"displayName":"박상우","userId":"00596815453416531190"},"user_tz":-540},"id":"tbVO_n8BQ1bc","outputId":"dc19a440-0231-40f8-eabb-a0c6b7c40e3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}],"source":["# GPU preparation\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using CPU instead.')"]},{"cell_type":"code","source":["# Debugging cell\n","import torch.nn.functional as F\n","\n","class MLPPClassifier(nn.Module):\n","    \"\"\" MBTI Binary Classifier \"\"\"\n","    def __init__(self, input_dim, n_layers, hidden_dim, num_classes = 2, dropout = 0.5):\n","        super(MLPPClassifier, self).__init__()\n","\n","        assert type(hidden_dim) == list, ValueError(\"hidden_dim should be list type\")\n","\n","        self.n_layers = n_layers            # number of layers\n","        self.hidden_dim = hidden_dim        # hidden dimension\n","        self.input_dim = input_dim          # input dimension\n","        self.num_classes = num_classes      # number of classes\n","        self.dropout = nn.Dropout(p=dropout, inplace=False)\n","        \n","        # dimension list for all layers \n","        self.dimensions = [self.input_dim] + self.hidden_dim + [self.num_classes]\n","\n","        # layer stacks\n","        self.layers = nn.ModuleList(\n","            [nn.Linear(self.dimensions[i - 1], self.dimensions[i]) for i in range(1, len(self.dimensions))])\n","\n","    def forward(self, x):\n","        for i, layer in enumerate(self.layers):\n","            x = x.to(torch.float32)\n","            x = layer(x)\n","\n","            # If layer is not the last layer\n","            if i != len(self.layers) - 1: \n","                x = self.dropout(F.relu(x))\n","\n","        return x"],"metadata":{"id":"-Rb115AcBeJ7","executionInfo":{"status":"ok","timestamp":1680543692191,"user_tz":-540,"elapsed":4,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# from mlp import MLPClassifier\n","\n","class BertWithMlp(BertForSequenceClassification):\n","    def __init__(\n","        self,\n","        config,\n","        input_dim = None,\n","        hidden_dim = None,\n","        num_classes = 2,\n","        dropout = 0.1\n","        ):\n","\n","        # ====================\n","        #      BERT Setup\n","        # ====================\n","\n","        # resulting BERT model is stored in 'self.bert'.\n","        super().__init__(config)\n","\n","        self.num_labels = config.num_labels\n","\n","        combined_feat_dim = config.text_feat_dim + config.cat_feat_dim + config.num_feat_dim\n","        print(\"combined_feat_dim :\", combined_feat_dim)\n","\n","        self.mlp = MLPPClassifier(\n","            combined_feat_dim,\n","            None,\n","            hidden_dim,\n","            num_classes=num_classes,\n","            dropout=dropout\n","        )\n","        print(\"mlp :\", self.mlp)\n","        self.dropout = nn.Dropout(p=dropout, inplace=False)\n","        self.bn = nn.BatchNorm1d(config.num_feat_dim)\n","\n","    def forward(\n","        self,\n","        input_ids = None,\n","        attention_mask = None,\n","        token_type_ids = None,\n","        position_ids = None,\n","        head_mask = None,\n","        inputs_embeds = None,\n","        labels = None,\n","        output_attentions = None,\n","        cat_feats = None,\n","        num_feats = None\n","    ):\n","        # ====================\n","        #     BERT forward\n","        # ====================\n","        #TODO: 더 많은 인자 추가해주기\n","        logits = self.bert(\n","            input_ids,\n","            token_type_ids=token_type_ids,\n","            attention_mask=attention_mask)\n","\n","        cls = logits[1]\n","        # print(\"logits :\", logits[0].shape, logits[1].shape)\n","        # Apply dropout to cls\n","        cls = self.dropout(cls)\n","        # Apply batch normalization to numerical features\n","        # num_feats = self.bn(num_feats)        # 여기 오류남. 왜인지 아직 확인 X\n","\n","        # print(\"cls shape :\", cls.shape)\n","        # print(\"cat shape :\", cat_feats.shape)\n","        # print(\"num shape :\", num_feats.shape)\n","\n","        # ====================\n","        #      MLP forward\n","        # ====================\n","        all_feats = torch.cat((cls, cat_feats.view(-1, 1), num_feats.view(-1, 1)), dim=1)\n","        # print(\"all_feats shape :\", all_feats.shape)\n","        output = self.mlp(all_feats)\n","\n","        return output\n"],"metadata":{"id":"ZpVnMOF-9yDs","executionInfo":{"status":"ok","timestamp":1680543692191,"user_tz":-540,"elapsed":4,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Update config file\n","from transformers import BertConfig\n","\n","#TODO: num_labels 인자가 필요한지 알아봐야 함\n","config = BertConfig.from_pretrained(\n","    env_dict['pretrained_url'],\n","    num_labels = 2\n","  )\n","\n","config.num_feat_dim = 1\n","config.cat_feat_dim = 1\n","config.text_feat_dim = config.hidden_size\n","\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHzf_UILKiZW","executionInfo":{"status":"ok","timestamp":1680543692191,"user_tz":-540,"elapsed":4,"user":{"displayName":"박상우","userId":"00596815453416531190"}},"outputId":"63ef1746-e0f5-41ac-f044-9d11d6ac18ad"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"cat_feat_dim\": 1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_feat_dim\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"text_feat_dim\": 768,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n"]}]},{"cell_type":"code","source":["# Prepare model\n","model = BertWithMlp.from_pretrained(\n","    env_dict['pretrained_url'],\n","    config      = config,\n","    hidden_dim  = env_dict['hidden_dim'],\n","    dropout     = env_dict['dropout']\n","    )\n","\n","model.cuda()\n","\n","# Apply weight decaying except for bias & layer normalization term\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","# Prepare optimizer\n","optimizer = AdamW(optimizer_grouped_parameters, lr=env_dict['lr'])\n","\n","criterion = nn.BCEWithLogitsLoss()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QwILgWVI-ma5","executionInfo":{"status":"ok","timestamp":1680544059686,"user_tz":-540,"elapsed":1704,"user":{"displayName":"박상우","userId":"00596815453416531190"}},"outputId":"d933a461-2a9e-431a-b1e2-e04455d21dbb"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["combined_feat_dim : 770\n","mlp : MLPPClassifier(\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (layers): ModuleList(\n","    (0): Linear(in_features=770, out_features=192, bias=True)\n","    (1): Linear(in_features=192, out_features=48, bias=True)\n","    (2): Linear(in_features=48, out_features=12, bias=True)\n","    (3): Linear(in_features=12, out_features=2, bias=True)\n","  )\n",")\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertWithMlp: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertWithMlp from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertWithMlp from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertWithMlp were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'bn.weight', 'mlp.layers.0.bias', 'mlp.layers.2.weight', 'mlp.layers.0.weight', 'mlp.layers.3.weight', 'mlp.layers.1.bias', 'mlp.layers.2.bias', 'bn.running_mean', 'mlp.layers.1.weight', 'bn.running_var', 'bn.bias', 'mlp.layers.3.bias', 'classifier.weight', 'bn.num_batches_tracked']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Freeze Encoder, use head's parameters only\n","free_encoder = False          # 이걸 True 로 바꾸면 학습 성과가 정말 떨어지더라..\n","\n","if free_encoder:\n","  for param in model.base_model.parameters():\n","    param.requires_grad = False"],"metadata":{"id":"aSqmFz0aiSph","executionInfo":{"status":"ok","timestamp":1680544089875,"user_tz":-540,"elapsed":1,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xsg8RoRjXjQE"},"source":["# Train"]},{"cell_type":"code","source":["def format_time(elapsed):\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"5LN0_mWU8Yvj","executionInfo":{"status":"ok","timestamp":1680543694014,"user_tz":-540,"elapsed":7,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Set the target of training right before training loop\n","env_dict['target_of_training'] = 'I/E'"],"metadata":{"id":"9Z6v5b5ukwBb","executionInfo":{"status":"ok","timestamp":1680544088127,"user_tz":-540,"elapsed":320,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["def one_hot_embedding(labels, num_classes, device):\n","    \"\"\"Embedding labels to one-hot form.\n","\n","    Args:\n","      labels: (LongTensor) class labels, sized [N,].\n","      num_classes: (int) number of classes.\n","\n","    Returns:\n","      (tensor) encoded labels, sized [N, #classes].\n","    \"\"\"\n","    y = torch.eye(num_classes, device=device) \n","    return y[labels]"],"metadata":{"id":"H-G4TQ5AJS-K","executionInfo":{"status":"ok","timestamp":1680543694014,"user_tz":-540,"elapsed":7,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Training Loop for 영도\n","model.train()\n","total_loss = 0\n","\n","for epoch in range(env_dict['epoch']):\n","  t0 = time.time()\n","  epoch_loss = 0\n","  for step, batch in tqdm(enumerate(train_dataloader)):\n","\n","    input_ids       = batch['input_ids'].to(device)\n","    token_type_ids  = batch['token_type_ids'].to(device)\n","    attention_mask  = batch['attention_mask'].to(device)\n","    cat_input       = batch['cat_input'].to(device)\n","    num_input       = batch['num_input'].to(device)\n","    label          = batch[env_dict['target_of_training']].to(device)\n","\n","    # Forward\n","    output = model(input_ids        = input_ids,\n","                    token_type_ids  = token_type_ids,\n","                    attention_mask  = attention_mask,\n","                    cat_feats       = cat_input,\n","                    num_feats       = num_input)\n","\n","    # Calculate loss\n","    loss = criterion(output, one_hot_embedding(label, 2, device))\n","    accu = torch.sum(torch.argmax(output, axis=1) == label).item() / env_dict['batch_size'] * 100\n","\n","    print(\"Step loss: {0:.2f}\".format(loss))\n","    print(\"Step accu: \", accu)\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    total_loss += loss\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  print(\"Epoch loss: {0:.2f}\".format(avg_train_loss))\n","  print(\"Training epoch took: {:}\".format(format_time(time.time() - t0)))"],"metadata":{"id":"_2U999FINgOv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1LUMI4BiZVac"},"source":["# Save trained model"]},{"cell_type":"code","source":["# Save\n","#TODO: haperparams가 이름에 드러날 수 있는 저장경로 생각해보기\n","# save_path = './models/' + env_dict['lm'] + 'with' + env_dict['classifier'] + '.pt'\n","\n","# torch.save({\n","#             'epoch': env_dict['epoch'],\n","#             'lr'   : env_dict['lr'],\n","#             'batch_size' : env_dict['batch_size'],\n","#             'free_encoder': free_encoder,\n","#             'model_state_dict': model.state_dict(),\n","#             'optimizer_state_dict': optimizer.state_dict()\n","#             }, save_path)"],"metadata":{"id":"_rnIRUdoNfSo","executionInfo":{"status":"ok","timestamp":1680545511877,"user_tz":-540,"elapsed":5768,"user":{"displayName":"박상우","userId":"00596815453416531190"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"qNF-ezn9RpXS"}},{"cell_type":"code","source":["test_dataset = MBTIDataset(\n","    data_path           = env_dict['test_path'],\n","    question_path       = env_dict['question_path'],\n","    pretrained_url      = env_dict['pretrained_url'],\n","    padding_per_batch   = env_dict['padding_per_batch'],\n","    is_train            = True\n",")\n","\n","data_collator = DataCollatorWithPadding(tokenizer=test_dataset.tokenizer) if env_dict['padding_per_batch'] else None\n","\n","# Dataloader\n","test_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size  = env_dict['batch_size'],\n","    shuffle     = env_dict['shuffle'],\n","    collate_fn  = data_collator\n",")"],"metadata":{"id":"Y2tv9NO1Romv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How to load saved model\n","# ref : https://pytorch.org/tutorials/beginner/saving_loading_models.html\n"],"metadata":{"id":"GKQmlFxRU0W-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장된 모델을 다른 파일에 불러와서 Test 하길 권장! (test.py 만들어도 좋아)\n","# Test cell for 영도\n","\n","model.test()\n","\n","for epoch in range(env_dict['epoch']):\n","  t0 = time.time()\n","  epoch_loss = 0\n","  for step, batch in tqdm(enumerate(train_dataloader)):\n","\n","    input_ids       = batch['input_ids'].to(device)\n","    token_type_ids  = batch['token_type_ids'].to(device)\n","    attention_mask  = batch['attention_mask'].to(device)\n","    cat_input       = batch['cat_input'].to(device)\n","    num_input       = batch['num_input'].to(device)\n","    label          = batch[env_dict['target_of_training']].to(device)\n","\n","    # Forward\n","    output = model(input_ids        = input_ids,\n","                    token_type_ids  = token_type_ids,\n","                    attention_mask  = attention_mask,\n","                    cat_feats       = cat_input,\n","                    num_feats       = num_input)\n","\n","    # Calculate loss\n","    loss = criterion(output, one_hot_embedding(label, 2, device))\n","    accu = torch.sum(torch.argmax(output, axis=1) == label).item() / env_dict['batch_size'] * 100\n","\n","    print(\"Step loss: {0:.2f}\".format(loss))\n","    print(\"Step accu: \", accu)\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    total_loss += loss\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  print(\"Epoch loss: {0:.2f}\".format(avg_train_loss))\n","  print(\"Training epoch took: {:}\".format(format_time(time.time() - t0)))"],"metadata":{"id":"RGy7ri7aRjed"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# K-Fold Cross Validation (수정 중)"],"metadata":{"id":"4iVUGgx9NXeT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-DVssQfmW8p"},"outputs":[],"source":["# Training with cross validation (ref : https://velog.io/@pppanghyun/6.-%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9DCross-Validation)\n","#TODO: Scheduler, Gradient Clipping\n","\n","kfold     = KFold(n_splits=5, shuffle=True)\n","criterion = torch.nn.MSELoss()\n","\n","validation_loss = []\n","\n","for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n","\n","    #TODO: Fold 끼리 겹칠 수 있음. 겹치지 않는 방식 고려 필요\n","    # Make indices for both training and validation\n","    train_subsampler  = SubsetRandomSampler(train_idx)\n","    val_subsampler    = SubsetRandomSampler(val_idx)\n","\n","    # Define dataloader using sampler\n","    train_dataloder = DataLoader(\n","        train_dataset,\n","        batch_size  = env_dict['batch_size'],\n","        shuffle     = env_dict['shuffle'],\n","        sampler     = train_subsampler,\n","        collate_fn  = data_collator\n","    )\n","    val_dataloder   = DataLoader(\n","        train_dataset,\n","        batch_size  = env_dict['batch_size'],\n","        shuffle     = env_dict['shuffle'],\n","        sampler     = val_subsampler,\n","        collate_fn  = data_collator\n","    )\n","\n","    # ===================\n","    #    Training Loop\n","    # ===================\n","\n","    optimizer = AdamW(model.parameters(), lr=env_dict['lr'], weight_decay=env_dict['decay_rate'])\n","\n","    model.train()\n","\n","    for epoch in range(env_dict['epoch']):\n","      t0 = time.time()\n","      epoch_loss = 0\n","      for step, batch in tqdm(enumerate(train_dataloader)):\n","\n","        input_ids       = batch['input_ids'].to(device)\n","        token_type_ids  = batch['token_type_ids'].to(device)\n","        attention_mask  = batch['attention_mask'].to(device)\n","        labels  = batch[env_dict['target_of_training']].to(device)\n","\n","        # Clear prior gradients\n","        model.zero_grad()\n","\n","        # Forward\n","        output = model(input_ids,\n","                       token_type_ids=token_type_ids,\n","                       attention_mask=attention_mask,\n","                       cat_feats=batch['cat_input'],\n","                       num_feats=batch['num_input'])\n","\n","        # Calculate loss\n","\n","        # loss    = outputs.loss     # Default : CELoss\n","\n","        print(\"Step loss: {0:.2f}\".format(loss))\n","\n","        loss.backward()\n","        optimizer.step()\n","      \n","      avg_train_loss = total_loss / len(train_dataloader)\n","      print(\"Epoch loss: {0:.2f}\".format(loss))\n","      print(\"Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","\n","#     train_rmse = evaluation(trainloader) # 학습 데이터의 RMSE\n","#     val_rmse = evaluation(valloader)\n","#     print(\"k-fold\", fold,\" Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse)) \n","#     validation_loss.append(val_rmse)\n","\n","## Calculate validation score\n","\n","# validation_loss = np.array(validation_loss)\n","# mean = np.mean(validation_loss)\n","# std = np.std(validation_loss)\n","# print(\"Validation Score: %.4f, ± %.4f\" %(mean, std))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7337906654535f92ad925780206611836a0922d3540b9d89ec64204ed4b58f9b"}}},"nbformat":4,"nbformat_minor":0}